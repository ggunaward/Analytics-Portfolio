{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f17f25f",
   "metadata": {},
   "source": [
    "Gavin Gunawardena \\\n",
    "INFS 770 \\\n",
    "Assignment 3 \\\n",
    "Dr. Liu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab967c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "from gensim.models import LdaModel, LsiModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9974b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#Task 1: Import Data\n",
    "docs = []\n",
    "directory = os.getcwd() + \"\\\\tp_dataset\"\n",
    "for filename in os.listdir(directory):\n",
    "    f = open(os.path.join(directory, filename), \"r\")\n",
    "    docs.append(f.read())\n",
    "\n",
    "#print number of items in the list to confirm whether it matches up\n",
    "#with the number of text files\n",
    "print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9cd4213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       able    accord       act    action  actually  additional    adjust  \\\n",
      "0  0.000000  0.025333  0.032976  0.000000  0.025333    0.032976  0.000000   \n",
      "1  0.000000  0.080357  0.000000  0.000000  0.026786    0.000000  0.000000   \n",
      "2  0.054252  0.000000  0.000000  0.054252  0.041677    0.000000  0.000000   \n",
      "3  0.000000  0.056784  0.000000  0.000000  0.000000    0.000000  0.000000   \n",
      "4  0.000000  0.000000  0.033851  0.000000  0.000000    0.033851  0.000000   \n",
      "5  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000  0.000000   \n",
      "6  0.062734  0.000000  0.000000  0.000000  0.048194    0.000000  0.000000   \n",
      "7  0.000000  0.066133  0.000000  0.043043  0.000000    0.000000  0.086086   \n",
      "8  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000  0.098844   \n",
      "\n",
      "   advisers    africa       age  ...    wealth   wealthy     weeks     white  \\\n",
      "0  0.000000  0.000000  0.000000  ...  0.028671  0.032976  0.025333  0.126664   \n",
      "1  0.121264  0.000000  0.000000  ...  0.030316  0.069734  0.080357  0.160715   \n",
      "2  0.094341  0.000000  0.000000  ...  0.047170  0.000000  0.000000  0.125032   \n",
      "3  0.000000  0.064268  0.160670  ...  0.000000  0.000000  0.000000  0.028392   \n",
      "4  0.029433  0.029433  0.088298  ...  0.000000  0.000000  0.026005  0.000000   \n",
      "5  0.000000  0.027428  0.054855  ...  0.000000  0.000000  0.145403  0.000000   \n",
      "6  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "7  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "8  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       wing     world     worry      year     years      york  \n",
      "0  0.028671  0.000000  0.000000  0.028671  0.050666  0.000000  \n",
      "1  0.060632  0.000000  0.000000  0.000000  0.000000  0.034867  \n",
      "2  0.047170  0.000000  0.000000  0.047170  0.041677  0.054252  \n",
      "3  0.000000  0.064268  0.000000  0.000000  0.056784  0.000000  \n",
      "4  0.000000  0.117731  0.033851  0.000000  0.000000  0.000000  \n",
      "5  0.000000  0.027428  0.000000  0.000000  0.072702  0.000000  \n",
      "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "7  0.000000  0.000000  0.043043  0.037425  0.000000  0.000000  \n",
      "8  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[9 rows x 419 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ggobl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'win', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "#Task 2: Write code to tokenize the docs using the TF-IDF vectorizer\n",
    "\n",
    "def before_token(documents):\n",
    "    # conver words to lower case\n",
    "    lower = map(str.lower, documents)\n",
    "    # remove puntuations\n",
    "    punctuationless = list(map(lambda x: \" \".join(re.findall('\\\\b\\\\w\\\\w+\\\\b',x)), lower))\n",
    "    # remove numbers\n",
    "    return list(map(lambda x:re.sub('\\\\b[0-9]+\\\\b', '', x), punctuationless))\n",
    "docs1 = before_token(docs)\n",
    "import nltk\n",
    "from nltk import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t,\"v\") for t in word_tokenize(doc)]\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "#remove words that appear in only one or two documents\n",
    "#remove words that appears in over 50% of documents\n",
    "vectorizer = TfidfVectorizer(tokenizer=LemmaTokenizer(),norm='l2',stop_words=stopwords, min_df=2, max_df=0.5)\n",
    "#vectorizer = TfidfVectorizer(tokenizer=LemmaTokenizer(),stop_words=stopwords)\n",
    "corpus_vect = vectorizer.fit_transform(docs1)\n",
    "df_vect = pd.DataFrame(corpus_vect.toarray(), columns=vectorizer.get_feature_names())\n",
    "#Print features\n",
    "print(df_vect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a79489",
   "metadata": {},
   "source": [
    "Task 3: Create a textbox and use your own language to discuss what TF-IDF means.\n",
    "\n",
    "*The idea of Term Frequency – Inverse Document Frequency is that if specific words occur in just a few documents, they might be useful for distinguishing some documents from others. This model utilizes the inverse document frequency formula to assign weights to words based on the total number of documents and how many documents contain the word.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49149a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{412: 'white', 166: 'house', 241: 'officials', 268: 'prepare', 269: 'present', 270: 'president', 36: 'biden', 391: 'trillion', 176: 'infrastructure', 185: 'job', 247: 'package', 280: 'profile', 106: 'domestic', 262: 'policy', 275: 'priorities', 148: 'free', 66: 'community', 64: 'college', 398: 'universal', 266: 'prekindergarten', 1: 'accord', 380: 'three', 132: 'familiar', 179: 'internal', 82: 'coronavirus', 311: 'relief', 257: 'piece', 238: 'next', 209: 'major', 203: 'legislative', 139: 'final', 288: 'push', 51: 'build', 31: 'back', 34: 'better', 11: 'agenda', 118: 'effort', 47: 'break', 143: 'focus', 56: 'child', 372: 'tax', 335: 'several', 417: 'years', 347: 'speak', 72: 'condition', 96: 'describe', 276: 'private', 81: 'conversations', 360: 'stress', 364: 'subject', 55: 'change', 12: 'aid', 396: 'unclear', 358: 'still', 144: 'follow', 411: 'weeks', 325: 'second', 74: 'confusion', 19: 'among', 76: 'congressional', 385: 'top', 37: 'bill', 131: 'face', 95: 'democrats', 322: 'scale', 312: 'republicans', 128: 'every', 406: 'vote', 167: 'however', 213: 'many', 52: 'campaign', 233: 'much', 94: 'democratic', 250: 'party', 182: 'introduce', 161: 'hike', 351: 'spend', 138: 'fight', 152: 'give', 35: 'beyond', 120: 'emergency', 248: 'pandemic', 85: 'country', 297: 'real', 340: 'since', 371: 'system', 83: 'could', 18: 'american', 212: 'manufacture', 86: 'crucial', 155: 'government', 90: 'decade', 229: 'moment', 93: 'decisions', 329: 'seek', 219: 'measure', 5: 'additional', 130: 'eye', 149: 'fund', 127: 'even', 304: 'reconciliation', 277: 'procedure', 251: 'pass', 330: 'senate', 271: 'press', 326: 'secretary', 184: 'jen', 286: 'psaki', 355: 'statement', 91: 'decide', 356: 'step', 373: 'team', 78: 'consider', 293: 'range', 265: 'potential', 244: 'options', 183: 'invest', 133: 'families', 307: 'reform', 63: 'code', 316: 'reward', 409: 'wealth', 243: 'ongoing', 350: 'speculation', 150: 'future', 113: 'economic', 283: 'proposals', 267: 'premature', 306: 'reflection', 379: 'think', 194: 'largely', 58: 'clean', 122: 'energy', 59: 'climate', 226: 'minority', 200: 'leader', 227: 'mitch', 217: 'mcconnell', 142: 'floor', 282: 'proposal', 4: 'actually', 392: 'trojan', 164: 'horse', 216: 'massive', 189: 'kill', 202: 'leave', 413: 'wing', 261: 'policies', 25: 'around', 169: 'hundreds', 39: 'billions', 318: 'roads', 48: 'bridge', 291: 'rail', 321: 'safety', 323: 'school', 174: 'income', 156: 'group', 38: 'billion', 115: 'education', 70: 'component', 309: 'relate', 313: 'research', 100: 'development', 13: 'aim', 119: 'electric', 30: 'available', 367: 'supply', 394: 'tuition', 53: 'care', 302: 'recently', 339: 'sign', 198: 'law', 416: 'year', 274: 'previously', 114: 'economy', 2: 'act', 305: 'reduce', 41: 'black', 222: 'menu', 292: 'raise', 295: 'rate', 252: 'percent', 410: 'wealthy', 172: 'immediately', 7: 'advisers', 186: 'joe', 333: 'separate', 188: 'key', 214: 'mark', 232: 'move', 387: 'toward', 140: 'finance', 208: 'longer', 418: 'york', 382: 'time', 315: 'review', 348: 'speaker', 258: 'pillar', 103: 'directly', 260: 'pledge', 178: 'intend', 342: 'slow', 278: 'process', 353: 'stage', 287: 'public', 256: 'phase', 75: 'congress', 23: 'april', 240: 'number', 308: 'regard', 341: 'size', 324: 'scope', 49: 'brief', 328: 'see', 97: 'design', 14: 'allow', 210: 'majority', 400: 'us', 207: 'long', 24: 'area', 338: 'side', 263: 'possibility', 159: 'hear', 231: 'months', 223: 'might', 50: 'bring', 345: 'something', 89: 'debate', 177: 'inside', 362: 'structure', 386: 'touch', 303: 'recommend', 44: 'boost', 33: 'begin', 151: 'giant', 407: 'washington', 264: 'post', 62: 'cnn', 234: 'national', 352: 'spokeswoman', 3: 'action', 290: 'question', 111: 'earlier', 0: 'able', 235: 'need', 299: 'rebuild', 236: 'never', 327: 'sector', 281: 'project', 137: 'federal', 27: 'astrazeneca', 402: 'vaccine', 337: 'show', 117: 'efficacy', 370: 'symptomatic', 105: 'disease', 336: 'severe', 165: 'hospitalization', 60: 'clinical', 389: 'trial', 67: 'company', 141: 'find', 249: 'participants', 73: 'confidence', 99: 'develop', 399: 'university', 246: 'oxford', 384: 'tolerate', 171: 'identify', 71: 'concern', 175: 'independent', 317: 'risk', 300: 'receive', 201: 'least', 108: 'dose', 88: 'data', 57: 'chile', 253: 'peru', 365: 'submit', 40: 'biopharmaceuticals', 28: 'authorization', 145: 'food', 110: 'drug', 157: 'half', 29: 'authorize', 397: 'unite', 354: 'state', 273: 'previous', 190: 'kingdom', 46: 'brazil', 346: 'south', 8: 'africa', 414: 'world', 310: 'release', 405: 'volunteer', 9: 'age', 146: 'four', 181: 'interval', 205: 'link', 160: 'higher', 242: 'older', 112: 'echo', 245: 'overall', 314: 'result', 84: 'countries', 193: 'lack', 390: 'trials', 357: 'stephen', 126: 'evans', 279: 'professor', 206: 'london', 170: 'hygiene', 393: 'tropical', 221: 'medicine', 220: 'media', 32: 'become', 125: 'european', 147: 'france', 368: 'suspend', 42: 'blood', 61: 'clot', 10: 'agency', 381: 'thursday', 116: 'effective', 272: 'prevent', 26: 'associate', 199: 'lead', 79: 'consistent', 361: 'strong', 109: 'dr', 254: 'peter', 375: 'tell', 237: 'news', 403: 'vaccines', 255: 'pfizer', 228: 'moderna', 187: 'johnson', 301: 'recent', 17: 'america', 153: 'global', 158: 'health', 285: 'provide', 20: 'anticipate', 363: 'study', 54: 'case', 401: 'vaccinate', 69: 'compare', 284: 'protect', 230: 'monitor', 334: 'serious', 294: 'rare', 204: 'like', 289: 'put', 80: 'continue', 129: 'evidence', 92: 'decision', 218: 'mean', 211: 'makers', 135: 'fda', 320: 'run', 173: 'important', 191: 'know', 123: 'especially', 415: 'worry', 366: 'suggest', 377: 'test', 65: 'comment', 124: 'ethnic', 68: 'comparable', 298: 'reassure', 98: 'detail', 77: 'connect', 408: 'watch', 15: 'along', 374: 'technology', 195: 'late', 215: 'market', 21: 'apart', 359: 'strategy', 404: 'variants', 383: 'today', 192: 'label', 43: 'bloomberg', 22: 'apple', 349: 'speakers', 163: 'homepod', 101: 'device', 136: 'feature', 344: 'software', 296: 'rather', 225: 'mini', 197: 'launch', 395: 'tv', 239: 'november', 162: 'home', 331: 'sensor', 376: 'temperature', 168: 'humidity', 87: 'currently', 180: 'internally', 104: 'discuss', 319: 'room', 378: 'thermostat', 6: 'adjust', 134: 'fan', 121: 'enable', 343: 'smart', 388: 'trail', 16: 'amazon', 196: 'latest', 332: 'sensors', 154: 'google', 102: 'devices', 224: 'millimeters', 45: 'bottom', 259: 'plastic', 107: 'dormant', 369: 'switch'}\n"
     ]
    }
   ],
   "source": [
    "#Task 4: Write code to convert the vectorized data to a gensim corpus object. \n",
    "#Print id2word\n",
    "from gensim import corpora\n",
    "word2id = dict((k, v) for k, v in vectorizer.vocabulary_.items())\n",
    "id2word = dict((v, k) for k,v in vectorizer.vocabulary_.items())\n",
    "d=corpora.Dictionary()\n",
    "d.id2token = id2word\n",
    "d.token2id = word2id\n",
    "corpus = gensim.matutils.Sparse2Corpus(corpus_vect, documents_columns=False)\n",
    "print(id2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189a1826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score for 1 topics: -17.093861\n",
      "Coherence Score for 2 topics: -7.251259\n",
      "Coherence Score for 3 topics: -4.578328\n",
      "Coherence Score for 4 topics: -3.783313\n",
      "Coherence Score for 5 topics: -3.619911\n",
      "Coherence Score for 6 topics: -3.219937\n",
      "Coherence Score for 7 topics: -3.599352\n"
     ]
    }
   ],
   "source": [
    "#Task 5: Write code to compute coherence scores for different numbers of topics including 2, 3, 4, and 5. \n",
    "from gensim.models import CoherenceModel\n",
    "for i in [1,2,3,4,5,6,7]:\n",
    "    cs = 0\n",
    "    for j in range(30):\n",
    "        lda = LdaModel(corpus, num_topics=i,id2word=id2word, passes=50)\n",
    "        #print(lda.print_topics())\n",
    "        coherence_model_lda = CoherenceModel(model=lda, corpus=corpus, dictionary=d, coherence='u_mass')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "        cs += coherence_lda\n",
    "    print('Coherence Score for %d topics: %f' % (i,cs/30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7143090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 topics:\n",
      "[(0, '0.008*\"apple\" + 0.008*\"sensor\" + 0.008*\"temperature\" + 0.007*\"home\" + 0.006*\"smart\" + 0.005*\"homepod\" + 0.005*\"humidity\" + 0.005*\"amazon\" + 0.005*\"room\" + 0.004*\"device\"'), (1, '0.002*\"device\" + 0.002*\"launch\" + 0.002*\"speakers\" + 0.002*\"mini\" + 0.002*\"feature\" + 0.002*\"software\" + 0.002*\"speaker\" + 0.002*\"bloomberg\" + 0.002*\"tv\" + 0.002*\"rather\"'), (2, '0.002*\"device\" + 0.002*\"launch\" + 0.002*\"speakers\" + 0.002*\"mini\" + 0.002*\"software\" + 0.002*\"feature\" + 0.002*\"speaker\" + 0.002*\"bloomberg\" + 0.002*\"rather\" + 0.002*\"tv\"'), (3, '0.011*\"vaccine\" + 0.008*\"biden\" + 0.008*\"infrastructure\" + 0.006*\"astrazeneca\" + 0.006*\"trial\" + 0.005*\"tax\" + 0.005*\"data\" + 0.005*\"house\" + 0.005*\"homepod\" + 0.005*\"spend\"')]\n",
      "Matrix for 4 topics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic: 1</th>\n",
       "      <th>topic: 2</th>\n",
       "      <th>topic: 3</th>\n",
       "      <th>topic: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic: 1  topic: 2  topic: 3  topic: 4\n",
       "0     0.023     0.023     0.023     0.931\n",
       "1     0.025     0.025     0.025     0.925\n",
       "2     0.025     0.025     0.025     0.926\n",
       "3     0.028     0.028     0.028     0.915\n",
       "4     0.026     0.026     0.026     0.923\n",
       "5     0.032     0.032     0.032     0.904\n",
       "6     0.047     0.045     0.045     0.864\n",
       "7     0.902     0.032     0.032     0.033\n",
       "8     0.890     0.037     0.037     0.037"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 topics:\n",
      "[(0, '0.009*\"vaccine\" + 0.007*\"sensor\" + 0.006*\"study\" + 0.005*\"smart\" + 0.005*\"home\" + 0.005*\"temperature\" + 0.005*\"astrazeneca\" + 0.005*\"apple\" + 0.004*\"countries\" + 0.004*\"case\"'), (1, '0.008*\"apple\" + 0.007*\"temperature\" + 0.006*\"home\" + 0.006*\"sensor\" + 0.006*\"homepod\" + 0.005*\"device\" + 0.004*\"thermostat\" + 0.004*\"feature\" + 0.004*\"software\" + 0.004*\"mini\"'), (2, '0.009*\"vaccine\" + 0.006*\"trial\" + 0.005*\"astrazeneca\" + 0.005*\"oxford\" + 0.005*\"unite\" + 0.004*\"age\" + 0.004*\"efficacy\" + 0.004*\"data\" + 0.004*\"medicine\" + 0.004*\"older\"'), (3, '0.012*\"biden\" + 0.011*\"infrastructure\" + 0.008*\"tax\" + 0.007*\"house\" + 0.007*\"homepod\" + 0.007*\"spend\" + 0.006*\"trillion\" + 0.006*\"white\" + 0.005*\"code\" + 0.005*\"proposal\"'), (4, '0.008*\"vaccine\" + 0.007*\"data\" + 0.007*\"trial\" + 0.006*\"dose\" + 0.006*\"efficacy\" + 0.005*\"give\" + 0.004*\"weeks\" + 0.004*\"longer\" + 0.004*\"interval\" + 0.004*\"fda\"'), (5, '0.002*\"suggest\" + 0.002*\"find\" + 0.002*\"launch\" + 0.002*\"speakers\" + 0.002*\"mean\" + 0.002*\"news\" + 0.002*\"like\" + 0.002*\"mini\" + 0.002*\"speaker\" + 0.002*\"number\"')]\n",
      "Matrix for 6 topics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic: 1</th>\n",
       "      <th>topic: 2</th>\n",
       "      <th>topic: 3</th>\n",
       "      <th>topic: 4</th>\n",
       "      <th>topic: 5</th>\n",
       "      <th>topic: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic: 1  topic: 2  topic: 3  topic: 4  topic: 5  topic: 6\n",
       "0     0.015     0.015     0.015     0.924     0.015     0.015\n",
       "1     0.016     0.016     0.016     0.919     0.016     0.016\n",
       "2     0.016     0.016     0.016     0.919     0.016     0.016\n",
       "3     0.019     0.019     0.907     0.019     0.019     0.019\n",
       "4     0.915     0.017     0.017     0.017     0.017     0.017\n",
       "5     0.021     0.021     0.021     0.021     0.895     0.021\n",
       "6     0.029     0.029     0.029     0.853     0.029     0.029\n",
       "7     0.022     0.893     0.021     0.021     0.021     0.021\n",
       "8     0.878     0.024     0.024     0.024     0.024     0.024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 topics:\n",
      "[(0, '0.009*\"vaccine\" + 0.008*\"apple\" + 0.006*\"temperature\" + 0.006*\"study\" + 0.006*\"home\" + 0.006*\"sensor\" + 0.006*\"astrazeneca\" + 0.005*\"homepod\" + 0.005*\"countries\" + 0.004*\"device\"'), (1, '0.009*\"vaccine\" + 0.008*\"data\" + 0.007*\"trial\" + 0.007*\"dose\" + 0.007*\"efficacy\" + 0.005*\"give\" + 0.004*\"weeks\" + 0.004*\"longer\" + 0.004*\"interval\" + 0.004*\"fda\"'), (2, '0.010*\"vaccine\" + 0.006*\"trial\" + 0.006*\"astrazeneca\" + 0.005*\"oxford\" + 0.005*\"unite\" + 0.004*\"age\" + 0.004*\"efficacy\" + 0.004*\"data\" + 0.004*\"medicine\" + 0.004*\"older\"'), (3, '0.014*\"biden\" + 0.013*\"infrastructure\" + 0.009*\"tax\" + 0.008*\"house\" + 0.008*\"spend\" + 0.007*\"trillion\" + 0.006*\"white\" + 0.006*\"proposal\" + 0.006*\"next\" + 0.005*\"republicans\"'), (4, '0.008*\"sensor\" + 0.007*\"smart\" + 0.007*\"home\" + 0.007*\"temperature\" + 0.006*\"apple\" + 0.005*\"currently\" + 0.005*\"trail\" + 0.005*\"amazon\" + 0.005*\"room\" + 0.005*\"humidity\"'), (5, '0.012*\"homepod\" + 0.007*\"software\" + 0.007*\"feature\" + 0.007*\"code\" + 0.006*\"apple\" + 0.006*\"could\" + 0.005*\"run\" + 0.004*\"relate\" + 0.004*\"future\" + 0.004*\"build\"'), (6, '0.002*\"speaker\" + 0.002*\"question\" + 0.002*\"april\" + 0.002*\"number\" + 0.002*\"design\" + 0.002*\"see\" + 0.002*\"boost\" + 0.002*\"describe\" + 0.002*\"since\" + 0.002*\"launch\"')]\n",
      "Matrix for 7 topics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic: 1</th>\n",
       "      <th>topic: 2</th>\n",
       "      <th>topic: 3</th>\n",
       "      <th>topic: 4</th>\n",
       "      <th>topic: 5</th>\n",
       "      <th>topic: 6</th>\n",
       "      <th>topic: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic: 1  topic: 2  topic: 3  topic: 4  topic: 5  topic: 6  topic: 7\n",
       "0     0.013     0.013     0.013     0.922     0.013     0.013     0.013\n",
       "1     0.014     0.014     0.014     0.916     0.014     0.014     0.014\n",
       "2     0.014     0.014     0.014     0.917     0.014     0.014     0.014\n",
       "3     0.016     0.016     0.905     0.016     0.016     0.016     0.016\n",
       "4     0.913     0.015     0.015     0.015     0.014     0.014     0.014\n",
       "5     0.018     0.892     0.018     0.018     0.018     0.018     0.018\n",
       "6     0.025     0.025     0.025     0.025     0.025     0.850     0.025\n",
       "7     0.890     0.018     0.018     0.018     0.018     0.018     0.018\n",
       "8     0.021     0.021     0.021     0.021     0.875     0.021     0.021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Task 6: You usually cannot rely on the coherence scores to determine the optional \n",
    "#number of topics. Next, you want to further compare the top 3 numbers \n",
    "#of topics with the highest coherence scores.\n",
    "for i in [4,6,7]:\n",
    "    lda = LdaModel(corpus, num_topics=i,id2word=id2word, random_state=10, passes=50) #\n",
    "    lda_docs = lda[corpus]\n",
    "    scores = np.round([[doc[1] for doc in row] for row in lda_docs], 3)\n",
    "    topics = list(range(1,i+1,1))\n",
    "    col_headers = map(lambda x: 'topic: ' + str(x), topics)\n",
    "    df_lda = pd.DataFrame(scores, columns=list(col_headers))\n",
    "    print('%d topics:' % (i))\n",
    "    print(lda.print_topics())\n",
    "    print('Matrix for %d topics:' % (i))\n",
    "    display(df_lda)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c991280",
   "metadata": {},
   "source": [
    "Task 7: Create a textbox and tell me among the top 3 numbers with the highest average coherence scores, which one gives you the best topic modeling results. \n",
    "\n",
    "*7 topics, as it gives more leeway for the chance that each or most of the documents are based on a different or slightly different topic, or consist of different subtopics. This hypothesis is reinforced by the fact that the document score table presents a score of .8 or more for each of the topic numbers except for 7. Also this detected pattern in the 7 topics column could indicate a 7th undetected topic that is a combination of subtopics and that would've been missed with a lower topic count.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb060a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accord</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>additional</th>\n",
       "      <th>adjust</th>\n",
       "      <th>advisers</th>\n",
       "      <th>africa</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>wealth</th>\n",
       "      <th>wealthy</th>\n",
       "      <th>weeks</th>\n",
       "      <th>white</th>\n",
       "      <th>wing</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 419 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    able  accord    act  action  actually  additional  adjust  advisers  \\\n",
       "0  0.020   0.049  0.017   0.020     0.031       0.017   0.016     0.069   \n",
       "1 -0.012  -0.003  0.003  -0.012    -0.020       0.003   0.001    -0.038   \n",
       "2  0.014   0.020 -0.004   0.017     0.007      -0.004   0.083    -0.017   \n",
       "3  0.057  -0.011  0.001  -0.005     0.043       0.001  -0.061    -0.005   \n",
       "4 -0.003   0.009 -0.036  -0.007     0.002      -0.036   0.001    -0.017   \n",
       "5 -0.054   0.081  0.002  -0.057    -0.014       0.002  -0.003     0.063   \n",
       "6 -0.002   0.112 -0.034   0.002     0.002      -0.034  -0.000     0.006   \n",
       "\n",
       "   africa    age  ...  wealth  wealthy  weeks  white   wing  world  worry  \\\n",
       "0   0.025  0.062  ...   0.031    0.030  0.065  0.127  0.040  0.043  0.011   \n",
       "1   0.039  0.098  ...  -0.024   -0.022  0.031 -0.082 -0.030  0.066  0.011   \n",
       "2  -0.007 -0.018  ...  -0.008   -0.007 -0.017 -0.032 -0.010 -0.012  0.019   \n",
       "3  -0.003 -0.007  ...  -0.001   -0.002 -0.004 -0.007 -0.002 -0.002 -0.004   \n",
       "4  -0.004 -0.040  ...  -0.000    0.011  0.143  0.010  0.005 -0.094 -0.036   \n",
       "5  -0.007 -0.014  ...  -0.016    0.080  0.090  0.040  0.021  0.016  0.007   \n",
       "6   0.051  0.125  ...   0.001    0.014 -0.115  0.059  0.010 -0.022 -0.023   \n",
       "\n",
       "    year  years   york  \n",
       "0  0.026  0.053  0.026  \n",
       "1 -0.017  0.021 -0.020  \n",
       "2  0.012 -0.015 -0.006  \n",
       "3 -0.004 -0.003 -0.002  \n",
       "4 -0.007  0.069  0.001  \n",
       "5 -0.056 -0.071 -0.012  \n",
       "6 -0.004  0.017  0.007  \n",
       "\n",
       "[7 rows x 419 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic/document table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>topic 5</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic 1  topic 2  topic 3  topic 4  topic 5  topic 6  topic 7\n",
       "0      1.0     -0.0     -0.0      0.0     -0.0     -0.0     -0.0\n",
       "1      1.0     -0.0     -0.0     -0.0      0.0      0.0      0.0\n",
       "2      1.0     -0.0     -0.0     -0.0     -0.0     -0.0     -0.0\n",
       "3      1.0      1.0     -0.0     -0.0     -0.0     -0.0      0.0\n",
       "4      1.0      1.0     -0.0      0.0     -0.0      0.0     -0.0\n",
       "5      0.0      1.0     -0.0     -0.0      0.0     -0.0     -0.0\n",
       "6      0.0      0.0      1.0      1.0      0.0      0.0      0.0\n",
       "7      0.0      0.0      1.0     -0.0     -0.0     -0.0      0.0\n",
       "8      0.0      0.0      1.0     -0.0      0.0      0.0     -0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Task 8: \tRun truncated SVD(set n_components to be the optimal number \n",
    "#of topics you found in T7) and print topics and the topic/document table.\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "tsvd = TruncatedSVD(n_components=7)\n",
    "tsvd.fit(corpus_vect)\n",
    "df_comp = pd.DataFrame(tsvd.components_, columns=vectorizer.get_feature_names())\n",
    "df_comp = df_comp.apply(lambda x: np.round(x,3))\n",
    "#print topics\n",
    "print('topics')\n",
    "display(df_comp)\n",
    "#print topic/document table\n",
    "scores = np.round(np.round(tsvd.transform(corpus_vect), 3))\n",
    "df_tsvd = pd.DataFrame(scores, columns=[\"topic 1\", \"topic 2\",\"topic 3\", \"topic 4\",\"topic 5\", \"topic 6\", \"topic 7\"])\n",
    "print('topic/document table:')\n",
    "display(df_tsvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2da7d209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.326*\"biden\" + 0.318*\"vaccine\" + 0.292*\"infrastructure\" + 0.185*\"tax\" + 0.177*\"house\" + 0.173*\"spend\" + 0.135*\"astrazeneca\" + 0.129*\"trillion\" + 0.128*\"trial\" + 0.127*\"white\"'),\n",
       " (1,\n",
       "  '0.502*\"vaccine\" + -0.233*\"biden\" + -0.221*\"infrastructure\" + 0.211*\"astrazeneca\" + 0.209*\"trial\" + 0.193*\"data\" + 0.176*\"efficacy\" + 0.153*\"dose\" + -0.139*\"tax\" + -0.133*\"house\"'),\n",
       " (2,\n",
       "  '-0.403*\"apple\" + -0.335*\"homepod\" + -0.313*\"sensor\" + -0.291*\"temperature\" + -0.271*\"home\" + -0.188*\"smart\" + -0.173*\"software\" + -0.173*\"feature\" + -0.157*\"device\" + -0.146*\"humidity\"'),\n",
       " (3,\n",
       "  '-0.486*\"homepod\" + -0.275*\"software\" + -0.275*\"feature\" + -0.267*\"code\" + 0.240*\"sensor\" + -0.222*\"could\" + 0.191*\"temperature\" + 0.187*\"home\" + -0.175*\"run\" + 0.171*\"smart\"'),\n",
       " (4,\n",
       "  '-0.358*\"trial\" + -0.344*\"data\" + 0.244*\"study\" + -0.225*\"efficacy\" + -0.200*\"dose\" + 0.196*\"astrazeneca\" + -0.185*\"give\" + 0.155*\"countries\" + -0.143*\"weeks\" + 0.142*\"johnson\"'),\n",
       " (5,\n",
       "  '0.242*\"proposal\" + 0.226*\"move\" + -0.205*\"infrastructure\" + 0.204*\"key\" + 0.204*\"agenda\" + 0.198*\"next\" + -0.180*\"vote\" + -0.179*\"republicans\" + 0.170*\"biden\" + 0.153*\"final\"'),\n",
       " (6,\n",
       "  '-0.300*\"study\" + -0.235*\"dose\" + 0.228*\"oxford\" + 0.221*\"unite\" + -0.182*\"fda\" + 0.176*\"us\" + 0.173*\"trial\" + -0.169*\"give\" + 0.141*\"trials\" + 0.138*\"state\"')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic/document table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>topic 5</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.752</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.722</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.507</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.484</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.188</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>-0.799</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.234</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.190</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.823</td>\n",
       "      <td>0.463</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic 1  topic 2  topic 3  topic 4  topic 5  topic 6  topic 7\n",
       "0    0.752   -0.492    0.146   -0.011    0.022   -0.076   -0.051\n",
       "1    0.722   -0.472    0.134    0.029   -0.083    0.451    0.081\n",
       "2    0.719   -0.500    0.141    0.013    0.044   -0.370   -0.016\n",
       "3    0.507    0.742    0.129    0.036    0.023   -0.074    0.407\n",
       "4    0.517    0.676    0.092   -0.007    0.454    0.097   -0.225\n",
       "5    0.484    0.693    0.112    0.012   -0.476   -0.029   -0.211\n",
       "6    0.188    0.022   -0.556   -0.799   -0.020    0.007    0.007\n",
       "7    0.234    0.018   -0.916    0.080    0.014   -0.014    0.032\n",
       "8    0.190    0.001   -0.823    0.463   -0.015    0.003   -0.029"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Task 8b: Using the LsiModel class to implement truncated SVD\n",
    "lsi = LsiModel(corpus=corpus, id2word=id2word, num_topics=7)\n",
    "\n",
    "\n",
    "#print topics\n",
    "display(lsi.print_topics(7))\n",
    "lsi_docs = lsi[corpus]\n",
    "\n",
    "#print topic/document table\n",
    "scores = np.round([[doc[1] for doc in row] for row in lsi_docs], 3)\n",
    "df_lsi = pd.DataFrame(scores, columns=[\"topic 1\", \"topic 2\",\"topic 3\", \"topic 4\",\"topic 5\", \"topic 6\", \"topic 7\"])\n",
    "print('topic/document table:')\n",
    "display(df_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48aea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

legend.text = rownames(PasswordDataEA1.2.df$subject), horizontal = TRUE, xlab = "Difference in Total Time Spent per Repetition (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Sessions (repetitions per session were averaged)", font = 4), )
boxplot(PasswordDataEA1.2.df$DiffBtwnLastFirst, density = 20,
boxwex = 0.5, col = c("blue"),
legend.text = rownames(PasswordDataEA1.2.df$subject), horizontal = TRUE, xlab = "Difference in Total Time Spent per Repetition (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Sessions (repetitions per session were averaged)", font = 4), )
boxplot(PasswordDataEA1.2.df$DiffBtwnLastFirst, density = 20,
boxwex = 0.5, col = c("blue"), "orange"),
boxplot(PasswordDataEA1.2.df$DiffBtwnLastFirst, density = 20,
boxwex = 0.5, col = c("blue"), fill = "orange",
legend.text = rownames(PasswordDataEA1.2.df$subject), horizontal = TRUE, xlab = "Difference in Total Time Spent per Repetition (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Sessions (repetitions per session were averaged)", font = 4), )
boxplot(PasswordDataEA1.2.df$DiffBtwnLastFirst, density = 20,
boxwex = 0.5, col = c("blue"), fill = c("orange"),
legend.text = rownames(PasswordDataEA1.2.df$subject), horizontal = TRUE, xlab = "Difference in Total Time Spent per Repetition (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Sessions (repetitions per session were averaged)", font = 4), )
#First, in order to explore the dataset, I'm going to create a few new datasets with the original dataset so that I can create visualizations of the data.
#This dataset, PasswordDataEA1.df, sums all of the password input actions to create a TotalTime column. Also, all of the password input action columns are removed.
PasswordDataEA1.3.df <- PasswordData.df
PasswordDataEA1.3.df$TotalTime <- rowSums(PasswordData.df[ , 4:ncol(PasswordData.df)])
PasswordDataEA1.df <- PasswordDataEA1.3.df[,c("subject","sessionIndex","rep","TotalTime")]
#This dataset, PasswordDataEA2.df, groups the original dataset by subject and sessionIndex and obtains the mean of each password input action under each subject/session group.
PasswordDataEA2.df <- PasswordData.df
PasswordDataEA2.df <- PasswordDataEA2.df %>%
group_by(subject, sessionIndex) %>%
summarise(across(H.period:H.Return, mean, .names = "{col}_mean"))
#This dataset, PasswordData_long.df, is just a long form version of the original dataset with just 5 columns: subject, sessionIndex, rep, action, time_spent
PasswordData_temp.df <- PasswordData.df
PasswordDataCols.df <- colnames(PasswordData.df)
PasswordData_long.df <-  PasswordData_temp.df %>%                                   # Apply pivot_longer function
pivot_longer(PasswordDataCols.df[4:34], names_to = "action", values_to = "time_spent")
#This dataset, PasswordDataEA1.1.df, takes the dataset I created earlier, PasswordDataEA1.df, which obtained the total times per repetition, groups it by subject and sessionIndex, and obtains the mean of total times per each subject/session group
PasswordDataEA1.1.df <- PasswordDataEA1.df %>%
group_by(subject, sessionIndex) %>%
summarise(Mean_TotalTime = mean(TotalTime))
#This dataset, PasswordDataEA1.2.df, takes PasswordDataEA1.1.df and obtains the difference in average total time spent per repetition between the last session and the first session for each subject
PasswordDataEA1.2.df <- PasswordDataEA1.1.df %>%
group_by(subject) %>%
mutate(DiffBtwnLastFirst = Mean_TotalTime[sessionIndex == 1] - Mean_TotalTime[sessionIndex == 8])
PasswordDataEA1.2.df <- unique(PasswordDataEA1.2.df[,c(1,4)])
#This dataset, PasswordDataEA1.3.df, includes subject, sessionIndex, the difference between the first and last repetitions of each session
PasswordDataEA1.3.df <- PasswordDataEA1.df %>%
group_by(subject,sessionIndex) %>%
mutate(DiffBtwnLastFirst = TotalTime[rep == 1] - TotalTime[rep == 50])
PasswordDataEA1.3.df <- unique(PasswordDataEA1.3.df[,c(1,2,5)])
PasswordDataEA1.3.df <- PasswordDataEA1.3.df %>%
group_by(subject) %>%
summarise(DiffBtwnLastFirst = mean(DiffBtwnLastFirst))
#Datasets created
# PasswordData.df
#
# PasswordDataEA1.df
#
# PasswordDataEA1.1.df
#
# PasswordDataEA1.2.df
#
# PasswordDataEA2.df
#
# PasswordDataEA1.3.df
#
# PasswordData_long.df
#Visualizations
#This box plot shows the difference in total time spent to type the password between the first and last repetition per session to show what improvement is seen within each session by each subject
boxplot(PasswordDataEA1.2.df$DiffBtwnLastFirst, density = 20,
boxwex = 0.5, col = c("blue"),
legend.text = rownames(PasswordDataEA1.2.df$subject), horizontal = TRUE, xlab = "Difference in Total Time Spent per Repetition (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Sessions (repetitions per session were averaged)", font = 4), )
#This box plot shows the average difference in total time spent to type the password between the first and last session of each subject
boxplot(PasswordDataEA1.3.df$DiffBtwnLastFirst, density = 20, col = c("blue"),
legend.text = rownames(PasswordDataEA1.3.df), horizontal = TRUE, xlab = "Difference in Total Time Spent (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Repetitions per Session", font = 4))
#This histogram with overlayed density plot shows the distribution of data and whether the Response Variable makes up a normal distribution
ggplot(PasswordDataEA1.df, aes(x=TotalTime)) +
geom_histogram(aes(y = ..density..), binwidth=.25, colour="black", fill="white") +
stat_function(fun = dnorm, lwd = 2, col = 'red',
args = list(mean = mean(PasswordDataEA1.df$TotalTime), sd = sd(PasswordDataEA1.df$TotalTime)))  +
labs(title = "Distribution of the response Variable (Total Time)")
#This box plot shows the average difference in total time spent to type the password between the first and last session of each subject
boxplot(PasswordDataEA1.3.df$DiffBtwnLastFirst, density = 20, col = c("cyan"),
legend.text = rownames(PasswordDataEA1.3.df), horizontal = TRUE, xlab = "Difference in Total Time Spent (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Repetitions per Session", font = 4))
#This box plot shows the average difference in total time spent to type the password between the first and last session of each subject
boxplot(PasswordDataEA1.3.df$DiffBtwnLastFirst, density = 20, col = c("light green"),
legend.text = rownames(PasswordDataEA1.3.df), horizontal = TRUE, xlab = "Difference in Total Time Spent (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Repetitions per Session", font = 4))
#This box plot shows the average difference in total time spent to type the password between the first and last session of each subject
boxplot(PasswordDataEA1.3.df$DiffBtwnLastFirst, density = 20, col = c("lime"),
legend.text = rownames(PasswordDataEA1.3.df), horizontal = TRUE, xlab = "Difference in Total Time Spent (seconds)", ylab = "Subjects")
#This box plot shows the average difference in total time spent to type the password between the first and last session of each subject
boxplot(PasswordDataEA1.3.df$DiffBtwnLastFirst, density = 20, col = c("lime green"),
legend.text = rownames(PasswordDataEA1.3.df), horizontal = TRUE, xlab = "Difference in Total Time Spent (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Repetitions per Session", font = 4))
#Visualizations
#This box plot shows the difference in total time spent to type the password between the first and last repetition per session to show what improvement is seen within each session by each subject
boxplot(PasswordDataEA1.2.df$DiffBtwnLastFirst, density = 20,
boxwex = 0.5, col = c("cyan"),
legend.text = rownames(PasswordDataEA1.2.df$subject), horizontal = TRUE, xlab = "Difference in Total Time Spent per Repetition (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Sessions (repetitions per session were averaged)", font = 4), )
#This box plot shows the average difference in total time spent to type the password between the first and last session of each subject
boxplot(PasswordDataEA1.3.df$DiffBtwnLastFirst, density = 20, col = c("lime green"),
legend.text = rownames(PasswordDataEA1.3.df), horizontal = TRUE, xlab = "Difference in Total Time Spent (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Repetitions per Session", font = 4))
#This box plot shows the difference in total time spent to type the password between the first and last repetition per session to show what improvement is seen within each session by each subject
boxplot(PasswordDataEA1.2.df$DiffBtwnLastFirst, density = 20,
boxwex = 0.5, col = c("orange"),
legend.text = rownames(PasswordDataEA1.2.df$subject), horizontal = TRUE, xlab = "Difference in Total Time Spent per Repetition (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Sessions (repetitions per session were averaged)", font = 4), )
#Visualizations
#This box plot shows the difference in total time spent to type the password between the first and last repetition per session to show what improvement is seen within each session by each subject
boxplot(PasswordDataEA1.2.df$DiffBtwnLastFirst, density = 20,
boxwex = 0.5, col = c("orange"),
legend.text = rownames(PasswordDataEA1.2.df$subject), horizontal = TRUE, xlab = "Difference in Total Time Spent per Repetition (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Sessions (repetitions per session were averaged)", font = 4), )
#This box plot shows the average difference in total time spent to type the password between the first and last session of each subject
boxplot(PasswordDataEA1.3.df$DiffBtwnLastFirst, density = 20, col = c("lime green"),
legend.text = rownames(PasswordDataEA1.3.df), horizontal = TRUE, xlab = "Difference in Total Time Spent (seconds)", ylab = "Subjects")
title(main = list("Average Improvement in Time Spent Between First and Last Repetitions per Session", font = 4))
#This histogram with overlayed density plot shows the distribution of data and whether the Response Variable makes up a normal distribution
ggplot(PasswordDataEA1.df, aes(x=TotalTime)) +
geom_histogram(aes(y = ..density..), binwidth=.25, colour="black", fill="white") +
stat_function(fun = dnorm, lwd = 2, col = 'red',
args = list(mean = mean(PasswordDataEA1.df$TotalTime), sd = sd(PasswordDataEA1.df$TotalTime)))  +
labs(title = "Distribution of the response Variable (Total Time)")
#This histogram with overlayed density plot shows the distribution of data and whether the Response Variable makes up a normal distribution
ggplot(PasswordDataEA1.df, aes(x=TotalTime)) +
geom_histogram(aes(y = ..density..), binwidth=.25, colour="black", fill="blue") +
stat_function(fun = dnorm, lwd = 2, col = 'red',
args = list(mean = mean(PasswordDataEA1.df$TotalTime), sd = sd(PasswordDataEA1.df$TotalTime)))  +
labs(title = "Distribution of the response Variable (Total Time)")
#This histogram with overlayed density plot shows the distribution of data and whether the Response Variable makes up a normal distribution
ggplot(PasswordDataEA1.df, aes(x=TotalTime)) +
geom_histogram(aes(y = ..density..), binwidth=.25, colour="black", fill="light blue") +
stat_function(fun = dnorm, lwd = 2, col = 'red',
args = list(mean = mean(PasswordDataEA1.df$TotalTime), sd = sd(PasswordDataEA1.df$TotalTime)))  +
labs(title = "Distribution of the response Variable (Total Time)")
knitr::opts_chunk$set(echo = TRUE)
#Suppress warnings
options(warn=-1)
# function to load and install packages if they don't exist
usePackage <- function(p) {
if (!is.element(p, installed.packages()[,1]))
install.packages(p, dep = TRUE)
require(p, character.only = TRUE)
}
# load packages used in this project
usePackage("tidyverse")
usePackage("ggplot2")
usePackage("knitr")
usePackage("plyr")
usePackage("dplyr")
usePackage("utils")
usePackage("rstatix")
#Suppress warnings
options(warn=-1)
# import the data
#Directly changed the file names so that they're all consistent with each other
# Format: Brand, "Pill", Pill number, Peak, "new.txt"
# e.g.: Bayer Pill 1 136.5 92.90 new.txt
#Made sure that the brand names are consistent on the files, since I'll be pulling the brand names from the file names
# Format the data into one big dataframe with no null values for easy querying by looping through each csv file and putting the aliquot times and intensities as well as other distinguishing details into separate columns
#Columns
# Brand
# Peak
# Replicant
# Aliquot
# Time
# Intensity
####
#Obtain the names and filepaths of the files
files <- list.files(path="./The trimed Datas copy", pattern="*.txt", full.names=TRUE, recursive = TRUE, include.dirs = TRUE)
# Create new empty Dataframe to dump all data into after initial cleaning
Data.All.df <- data.frame(matrix(ncol=6, nrow=0))
#Set the column names of the new data frame
colnames(Data.All.df) <- c('Brand','Peak','Replicant','Aliquot','Time','Intensity')
# Start recursion of files  to pull their data into the dataframe
for (f in 1:length(files)) {
t <- read.table(files[f], header=TRUE, sep = "\t", fill = TRUE) # load file
#Remove unnecessary columns
test.df <- t[,3:8]
#Remove null values and add columns for Aliquot times and intensities to variables
AT1 <- test.df[,1][!is.na(test.df[,1])]
AI1 <- test.df[,2][!is.na(test.df[,2])]
AT2 <- test.df[,3][!is.na(test.df[,3])]
AI2 <- test.df[,4][!is.na(test.df[,4])]
AT3 <- test.df[,5][!is.na(test.df[,5])]
AI3 <- test.df[,6][!is.na(test.df[,6])]
#New rows Aliquot 1
# Start recursion of rows in each variable
for (r in 1:length(AT1)){
#Create a new row of data to add to the dataframe
new_row <- c(
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][1], #Pull brand from the file path
paste(strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][4],strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][5]), #Pull peak from the file path
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][3], #Pull replicant number from the file path
1, #Aliquot number
AT1[r], #Aliquot time
AI1[r]) #Aliquot intensity
Data.All.df[nrow(Data.All.df) + 1,]  <- new_row #Add the above data to a new row
}
#New rows Aliquot 2
for (r in 1:length(AT2)){
new_row <- c(
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][1],
paste(strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][4],strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][5]),
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][3],
2,
AT2[r],
AI2[r])
Data.All.df[nrow(Data.All.df) + 1,]  <- new_row
}
#New rows Aliquot 3
colnames(Data.All.df) <- c('Brand','Peak','Replicant','Aliquot','Time','Intensity')
for (r in 1:length(AT3)){
new_row <- c(
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][1],
paste(strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][4],strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][5]),
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][3],
3,
AT3[r],
AI3[r])
Data.All.df[nrow(Data.All.df) + 1,]  <- new_row
}
}
knitr::opts_chunk$set(echo = TRUE)
#Suppress warnings
options(warn=-1)
# function to load and install packages if they don't exist
usePackage <- function(p) {
if (!is.element(p, installed.packages()[,1]))
install.packages(p, dep = TRUE)
require(p, character.only = TRUE)
}
# load packages used in this project
usePackage("tidyverse")
usePackage("ggplot2")
usePackage("knitr")
usePackage("plyr")
usePackage("dplyr")
usePackage("utils")
usePackage("rstatix")
#Suppress warnings
options(warn=-1)
# import the data
#Directly changed the file names so that they're all consistent with each other
# Format: Brand, "Pill", Pill number, Peak, "new.txt"
# e.g.: Bayer Pill 1 136.5 92.90 new.txt
#Made sure that the brand names are consistent on the files, since I'll be pulling the brand names from the file names
# Format the data into one big dataframe with no null values for easy querying by looping through each csv file and putting the aliquot times and intensities as well as other distinguishing details into separate columns
#Columns
# Brand
# Peak
# Replicant
# Aliquot
# Time
# Intensity
####
#Obtain the names and filepaths of the files
files <- list.files(path="./The trimed Datas copy", pattern="*.txt", full.names=TRUE, recursive = TRUE, include.dirs = TRUE)
# Create new empty Dataframe to dump all data into after initial cleaning
Data.All.df <- data.frame(matrix(ncol=6, nrow=0))
#Set the column names of the new data frame
colnames(Data.All.df) <- c('Brand','Peak','Replicant','Aliquot','Time','Intensity')
# Start recursion of files  to pull their data into the dataframe
for (f in 1:length(files)) {
t <- read.table(files[f], header=TRUE, sep = "\t", fill = TRUE) # load file
#Remove unnecessary columns
test.df <- t[,3:8]
#Remove null values and add columns for Aliquot times and intensities to variables
AT1 <- test.df[,1][!is.na(test.df[,1])]
AI1 <- test.df[,2][!is.na(test.df[,2])]
AT2 <- test.df[,3][!is.na(test.df[,3])]
AI2 <- test.df[,4][!is.na(test.df[,4])]
AT3 <- test.df[,5][!is.na(test.df[,5])]
AI3 <- test.df[,6][!is.na(test.df[,6])]
#New rows Aliquot 1
# Start recursion of rows in each variable
for (r in 1:length(AT1)){
#Create a new row of data to add to the dataframe
new_row <- c(
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][1], #Pull brand from the file path
paste(strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][4],strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][5]), #Pull peak from the file path
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][3], #Pull replicant number from the file path
1, #Aliquot number
AT1[r], #Aliquot time
AI1[r]) #Aliquot intensity
Data.All.df[nrow(Data.All.df) + 1,]  <- new_row #Add the above data to a new row
}
#New rows Aliquot 2
for (r in 1:length(AT2)){
new_row <- c(
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][1],
paste(strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][4],strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][5]),
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][3],
2,
AT2[r],
AI2[r])
Data.All.df[nrow(Data.All.df) + 1,]  <- new_row
}
#New rows Aliquot 3
colnames(Data.All.df) <- c('Brand','Peak','Replicant','Aliquot','Time','Intensity')
for (r in 1:length(AT3)){
new_row <- c(
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][1],
paste(strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][4],strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][5]),
strsplit(sapply(strsplit(files[f], "/"), tail, 1)," ")[[1]][3],
3,
AT3[r],
AI3[r])
Data.All.df[nrow(Data.All.df) + 1,]  <- new_row
}
}
# Adjust datatypes of the dataframe
Data.All.df$Replicant <- as.numeric(Data.All.df$Replicant)
Data.All.df$Aliquot <- as.numeric(Data.All.df$Aliquot)
Data.All.df$Time <- as.numeric(Data.All.df$Time)
Data.All.df$Intensity <- as.numeric(Data.All.df$Intensity)
#####
#Check for any null values to fix
cbind(
lapply(
lapply(Data.All.df, is.na)
, sum)
)
# Check for duplicate values to fix
length(Data.All.df[duplicated(Data.All.df)])
# Obtain a summary of the data
summary(Data.All.df)
#Suppress warnings
options(warn=-1)
# Utilizing scatter/line plot to compare the different brands of aspirin to see if there's an obvious difference between them and to check for outliers/noise. The intensities(small circles) along with the mean(large circles) are being shown at each time point for each brand/peak combination and for each replicant and aliquot. The line plot is just of the mean of each brand at each time point within the peak. The lowest intensity, highest intensity, and the mean  at a time point for a brand/peak combination is reflected in the graphs. The three horizontal lines show the overall mean for each brand at the peak.
#Looping through each peak via lapply to create the same chart for each one
df.2.LineScatter <-  function(df) {
lapply(unique(df$Peak), function(i)  df[df$Peak == i, ]  %>%
ggplot( aes(x=Time, y=Intensity, group=Brand, color=Brand)) +
geom_point() + stat_summary(geom="point",fun="mean",shape=19,size=4) +
stat_summary(geom="line",fun="mean",size=1) +
stat_smooth(method="lm", formula=y~1, se=FALSE) +
labs(title = paste("Intensities and their Averages At Each Time Point For Each Brand at ", i), colour = "Brand", y= "Intensity")
)
}
df.2.LineScatter(Data.All.df)
#Suppress warnings
options(warn=-1)
# Create version of the dataset without outliers
#Outliers here are intensities in each aliquot that are either above 1.5 times the interquartile range plus the third quartile or below 1.5 times the interquartile range minus the first quartile. (Q3 + 1.5xIQR or below Q1 - 1.5xIQR)
#Create function to remove outliers
remove_outliers_aspirin_dataset <- function(x.df){
#Create temporary dataset with row numbers as a column
Data.All.df.No.Outliers.Temp <- x.df
Data.All.df.No.Outliers.Temp$row_names <- row.names(Data.All.df.No.Outliers.Temp)
#Identify the values in each aliquot that are outliers
Data.All.df.No.Outliers.Temp2 <- Data.All.df.No.Outliers.Temp %>%
group_by(Peak, Brand, Replicant, Aliquot) %>%
identify_outliers("Intensity")
#Use recursion to rerun the function for identifying and removing outliers in case there are any left after each run
while (length(Data.All.df.No.Outliers.Temp2[,1]) > 0)
{
# create a list of all row numbers that are outliers
list.outliers <- as.list(Data.All.df.No.Outliers.Temp2$row_names)
# Remove the outliers from the main dataset based on the row numbers of outliers list
Data.All.df.No.Outliers.Temp <- Data.All.df.No.Outliers.Temp[!Data.All.df.No.Outliers.Temp$row_names %in% list.outliers,]
#Identify the values in each aliquot that are outliers
Data.All.df.No.Outliers.Temp2 <- Data.All.df.No.Outliers.Temp %>%
group_by(Peak, Brand, Replicant, Aliquot) %>%
identify_outliers("Intensity")
}
return(Data.All.df.No.Outliers.Temp)
}
# Run function to remove outliers
Data.All.df.No.Outliers <- remove_outliers_aspirin_dataset(Data.All.df)
# Check that the outliers are gone from the Data.All.df.No.Outliers dataset by looking at one of the box plots from the previous section that had obvious outliers
f.query <- subset(Data.All.df.No.Outliers, (Peak == '136.5 92.90' & Brand == 'Bayer'), select=c(Peak, Brand, Replicant, Aliquot, Intensity))
ggplot(f.query, aes(x=Intensity, y=paste(Peak," ",Brand," Pill ",Replicant, " ", Aliquot), fill=Aliquot)) +
labs(x="Intensity", y="Peak Brand Replicant Aliquot", title ="Data Without Outliers") +
geom_boxplot(outlier.colour = "red", outlier.shape = 1)
f.query <- subset(Data.All.df.No.Outliers, (Peak == '136.5 92.90' & Brand == 'P.V'), select=c(Peak, Brand, Replicant, Aliquot, Intensity))
ggplot(f.query, aes(x=Intensity, y=paste(Peak," ",Brand," Pill ",Replicant, " ", Aliquot), fill=Aliquot)) +
labs(x="Intensity", y="Peak Brand Replicant Aliquot", title="Data Without Outliers") +
geom_boxplot(outlier.colour = "red", outlier.shape = 1)
f.query <- subset(Data.All.df.No.Outliers, (Peak == '136.5 92.90' & Brand == 'Wal'), select=c(Peak, Brand, Replicant, Aliquot, Intensity))
ggplot(f.query, aes(x=Intensity, y=paste(Peak," ",Brand," Pill ",Replicant, " ", Aliquot), fill=Aliquot)) +
labs(x="Intensity", y="Peak Brand Replicant Aliquot", title="Data Without Outliers") +
geom_boxplot(outlier.colour = "red", outlier.shape = 1)
#Original Dataset
f.query <- subset(Data.All.df, (Peak == '136.5 92.90' & Brand == 'Bayer'), select=c(Peak, Brand, Replicant, Aliquot, Intensity))
ggplot(f.query, aes(x=Intensity, y=paste(Peak," ",Brand," Pill ",Replicant, " ", Aliquot), fill=Aliquot)) +
labs(x="Intensity", y="Peak Brand Replicant Aliquot", title="Data With Outliers") +
geom_boxplot(outlier.colour = "red", outlier.shape = 1)
f.query <- subset(Data.All.df, (Peak == '136.5 92.90' & Brand == 'P.V'), select=c(Peak, Brand, Replicant, Aliquot, Intensity))
ggplot(f.query, aes(x=Intensity, y=paste(Peak," ",Brand," Pill ",Replicant, " ", Aliquot), fill=Aliquot)) +
labs(x="Intensity", y="Peak Brand Replicant Aliquot", title="Data With Outliers") +
geom_boxplot(outlier.colour = "red", outlier.shape = 1)
f.query <- subset(Data.All.df, (Peak == '136.5 92.90' & Brand == 'Wal'), select=c(Peak, Brand, Replicant, Aliquot, Intensity))
ggplot(f.query, aes(x=Intensity, y=paste(Peak," ",Brand," Pill ",Replicant, " ", Aliquot), fill=Aliquot)) +
labs(x="Intensity", y="Peak Brand Replicant Aliquot", title="Data With Outliers") +
geom_boxplot(outlier.colour = "red", outlier.shape = 1)
#Suppress warnings
options(warn=-1)
# Obtain the AUCs by taking each aliquot from the dataset and averaging them individually.
#With outliers
Aliquots_AUP <- ddply(Data.All.df, .(Peak, Brand, Replicant, Aliquot), summarize,
Count = length(Intensity),
SD = round(sd(Intensity),2),
AUP = round(mean(Intensity), 2))
#Without outliers
Aliquots_AUP.No.Outliers <- ddply(Data.All.df.No.Outliers, .(Peak, Brand, Replicant, Aliquot), summarize,
Count = length(Intensity),
SD = round(sd(Intensity),2),
AUP = round(mean(Intensity), 2))
#Check the variance and standard deviation between the AUPs of the 3 aliquots for each replicant and average it
# With outliers
Avg.SD.AUP.With.Outliers <- mean(ddply(Aliquots_AUP, .(Peak, Brand, Replicant), summarize,
SD_AUP = round(sd(AUP),2),
Var_AUP = round(var(AUP),2))[,"SD_AUP"])
Avg.VAR.AUP.With.Outliers <- mean(ddply(Aliquots_AUP, .(Peak, Brand, Replicant), summarize,
SD_AUP = round(sd(AUP),2),
Var_AUP = round(var(AUP),2))[,"Var_AUP"])
# Without outliers
Avg.SD.AUP.Without.Outliers <- mean(ddply(Aliquots_AUP.No.Outliers, .(Peak, Brand, Replicant), summarize,
SD_AUP = round(sd(AUP),2),
Var_AUP = round(var(AUP),2))[,"SD_AUP"])
Avg.VAR.AUP.Without.Outliers <- mean(ddply(Aliquots_AUP.No.Outliers, .(Peak, Brand, Replicant), summarize,
SD_AUP = round(sd(AUP),2),
Var_AUP = round(var(AUP),2))[,"Var_AUP"])
#Summarize the data in a results table
Results_Table <- data.frame(Method=
c('With Outliers',
'Without Outliers'),
Standard_Deviation = c(Avg.SD.AUP.With.Outliers,Avg.SD.AUP.Without.Outliers),
Variance=c(Avg.VAR.AUP.With.Outliers,Avg.VAR.AUP.Without.Outliers))
kable1 <- kable(Results_Table, caption="Variance and Standard Deviation of the Aliquots, Grouped by Peak, Brand, and Replicant", format = "simple")
kable1
#Here I ran a  ANOVA test with no adjustments for Type I Error Rate:
# Compute the one way analysis of variance with outliers
res.aov <- aov(AUP ~ Brand, data = Aliquots_AUP)
# Summary of the analysis
summary(res.aov)
#Pairwise analysis of variance with outliers
pairwise.t.test(Aliquots_AUP$AUP, Aliquots_AUP$Brand, p.adjust.method="none")
# Compute the one way analysis of variance without outliers to check if Brand has an effect
res.aov <- aov(AUP ~ Brand, data = Aliquots_AUP.No.Outliers)
# Summary of the analysis
summary(res.aov)
#Pairwise analysis of variance without outliers
pairwise.t.test(Aliquots_AUP.No.Outliers$AUP, Aliquots_AUP.No.Outliers$Brand, p.adjust.method="none")
#Create a table with the results
Results_Table <- data.frame(Brand=c('Brand - With Outliers', 'Brand - w/o Outliers', 'P.V. vs Bayer - With Outliers','Wal vs Bayer - With Outliers','Wal vs P.V. - With Outliers', 'P.V. vs Bayer - w/o Outliers','Wal vs Bayer - w/o Outliers','Wal vs P.V - w/o Oultiers'),AoV_P_Value=c(0.973,0.729,'','','','','',''),
Pairwise_T_Test_P_Value = c('','',0.85,0.98,0.83,0.53,0.46,0.91)
)
kable4 <- kable(Results_Table, caption="ANOVA and T-Test Results Summary", format = "simple")
kable4
#Suppress warnings
options(warn=-1)
#ANOVA Analysis
# Conduct a Tukey-Kramer test to make pairwise comparisons of the 3 Brands
TukeyHSD(res.aov)$Brand
# Conduct a  Bonferroni  test to make pairwise comparisons of the 3 Brands
Aliquots_AUP %>%
pairwise_t_test(
AUP ~ Brand,
paired = TRUE,
p.adjust.method = "holm",
pool.sd = TRUE
)
# Conduct a Tukey-Kramer test to make pairwise comparisons of the 3 Brands
TukeyHSD(res.aov)$Brand
# Conduct a  Bonferroni  test to make pairwise comparisons of the 3 Brands
Aliquots_AUP.No.Outliers %>%
pairwise_t_test(
AUP ~ Brand,
paired = TRUE,
p.adjust.method = "holm",
pool.sd = TRUE
)
#Display the P values in a results table:
Results_Table <- data.frame(Brand=c('P.V. vs Bayer - With Outliers','Wal vs Bayer - With Outliers','Wal vs P.V. - With Outliers', 'P.V. vs Bayer - w/o Outliers','Wal vs Bayer - w/o Outliers','Wal vs P.V - w/o Oultiers'),Tukey_Kramer=c(0.489,0.984,0.389,0.078,0.030,0.924),
Bonferroni = c(0.818,0.887,0.118,0.140,0.132,0.624)
)
kable2 <- kable(Results_Table, caption="Ad-Hoc Test Results Summary", format = "simple")
kable2
Avg.SD.AUP.Without.Outliers
Avg.VAR.AUP.Without.Outliers
Avg.VAR.AUP.With.Outliers
Avg.VAR.AUP.Without.Outliers
kable1
Aliquots_AUP.No.Outliers
Aliquots_AUP
Aliquots_AUP.No.Outliers
Aliquots_AUP
kable1
Avg.VAR.AUP.Without.Outliers
Aliquots_AUP.No.Outliers
Avg.VAR.AUP.Without.Outliers
Aliquots_AUP.No.Outliers
Avg.VAR.AUP.Without.Outliers
mean(ddply(Aliquots_AUP.No.Outliers, .(Peak, Brand, Replicant), summarize,
SD_AUP = round(sd(AUP),2),
Var_AUP = round(var(AUP),2))
ddply(Aliquots_AUP.No.Outliers, .(Peak, Brand, Replicant), summarize,
mean(ddply(Aliquots_AUP.No.Outliers, .(Peak, Brand, Replicant), summarize,
SD_AUP = round(sd(AUP),2),
Var_AUP = round(var(AUP),2)))
mean(ddply(Aliquots_AUP.No.Outliers, .(Peak, Brand, Replicant), summarize,
SD_AUP = round(sd(AUP),2),
Var_AUP = round(var(AUP),2))[,:])
mean(ddply(Aliquots_AUP.No.Outliers, .(Peak, Brand, Replicant), summarize,
SD_AUP = round(sd(AUP),2),
Var_AUP = round(var(AUP),2))[,"Var_AUP"])
mean(ddply(Aliquots_AUP.No.Outliers, .(Peak, Brand, Replicant), summarize,
SD_AUP = round(sd(AUP),2)[,"SD_AUP"],
Var_AUP = round(var(AUP),2)))
